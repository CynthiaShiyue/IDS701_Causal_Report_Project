{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fad8f9ef",
   "metadata": {},
   "source": [
    "##  Variable Definitions & Formulas\n",
    "\n",
    "| Variable              | Definition / Formula |\n",
    "|-----------------------|----------------------|\n",
    "| `Date`                | Trading calendar date of the stock |\n",
    "| `ticker`              | Ticker symbol of the stock (e.g., NVDA, PLTR) |\n",
    "| `Close`               | Closing price of the stock on a given day |\n",
    "| `Return`              | Daily return of the stock:  $R_{i,t} = \\frac{P_{i,t} - P_{i,t-1}}{P_{i,t-1}}$ |\n",
    "| `expected_return`     | Rolling expected return from estimation window:  $\\bar{R}_i = \\frac{1}{T} \\sum_{t=-90}^{-30} R_{i,t}$ |\n",
    "| `abnormal_return` (AR)| Abnormal return:  $AR_{i,t} = R_{i,t} - \\bar{R}_i$ |\n",
    "| `event_id`            | Event identifier (e.g., `2022_export_control`) |\n",
    "| `event_date`          | Announcement date of trade policy shock |\n",
    "| `event_time`          | Time relative to event: $t = \\text{Date} - \\text{event\\_date}$ |\n",
    "| `CAR_pre`             | Cumulative Abnormal Return pre-event: $\\sum_{t=-7}^{-1} AR_{i,t}$ |\n",
    "| `CAR_post`            | Cumulative Abnormal Return post-event: $\\sum_{t=0}^{7} AR_{i,t}$ |\n",
    "| `delta_CAR`           | Difference-in-differences outcome: $CAR_{\\text{post}} - CAR_{\\text{pre}}$ |\n",
    "| `post`                | Event-time indicator: $1$ if $t \\geq 0$, else $0$ |\n",
    "| `CAR` (custom window) | Total abnormal return over user-defined window: $\\sum_{t=a}^{b} AR_{i,t}$ |\n",
    "| `Treatment`           | Group indicator: $1$ if firm is hardware-dependent, else $0$ |\n",
    "| `Treatment × post`    | Interaction term: $Treatment_i \\times post_{it}$, used for DiD |\n",
    "| `firm_FE`             | Firm fixed effect (optional, for regression control of firm-level heterogeneity) |\n",
    "| `event_FE`            | Event fixed effect (optional, for regression control of event-level shocks) |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "21f3e0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def daily_return_price(ticker, start_date, end_date, treatment_flag):\n",
    "    \"\"\"\n",
    "    Fetches historical price and computes daily return for a given ticker.\n",
    "\n",
    "    Parameters:\n",
    "        ticker (str): Stock symbol, e.g., 'NVDA'\n",
    "        start_date (str): Start date in 'YYYY-MM-DD' format\n",
    "        end_date (str): End date in 'YYYY-MM-DD' format\n",
    "        treatment_flag (int): 1 if hardware-dependent (treatment), 0 if control\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Columns = ['Date', 'ticker', 'Close', 'Return', 'Treatment']\n",
    "    \"\"\"\n",
    "    stock = yf.Ticker(ticker)\n",
    "    price_df = stock.history(start=start_date, end=end_date)\n",
    "\n",
    "    df = price_df.copy()\n",
    "    df[\"Return\"] = df[\"Close\"].pct_change()\n",
    "    df[\"ticker\"] = ticker\n",
    "    df[\"Treatment\"] = treatment_flag\n",
    "    df = df.reset_index()  # turn 'Date' from index to column\n",
    "\n",
    "    return df[[\"Date\", \"ticker\", \"Close\", \"Return\", \"Treatment\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "41bf3b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_expected_return_rolling(df, estimation_start=-90, estimation_end=-30):\n",
    "    \"\"\"\n",
    "    For each row, compute expected return by averaging the returns of the same ticker\n",
    "    in the range [Date + estimation_start, Date + estimation_end].\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): Must include ['Date', 'ticker', 'Return']\n",
    "        estimation_start (int): Start of look-back window (e.g., -90)\n",
    "        estimation_end (int): End of look-back window (e.g., -30)\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with 'expected_return' and 'abnormal_return'\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "    df = df.sort_values([\"ticker\", \"Date\"])\n",
    "\n",
    "    # Multi-index for efficient slicing\n",
    "    df_indexed = df.set_index([\"ticker\", \"Date\"]).sort_index()\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        ticker = row[\"ticker\"]\n",
    "        date = row[\"Date\"]\n",
    "\n",
    "        start_date = date + pd.Timedelta(days=estimation_start)\n",
    "        end_date = date + pd.Timedelta(days=estimation_end)\n",
    "\n",
    "        try:\n",
    "            history_returns = df_indexed.loc[ticker].loc[start_date:end_date][\"Return\"]\n",
    "            expected = history_returns.mean()\n",
    "        except:\n",
    "            expected = None\n",
    "\n",
    "        row[\"expected_return\"] = expected\n",
    "        row[\"abnormal_return\"] = (\n",
    "            row[\"Return\"] - expected if pd.notnull(expected) else pd.NA\n",
    "        )\n",
    "        result.append(row)\n",
    "\n",
    "    return pd.DataFrame(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "a1613021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_event_info_all_rows(df, event_dict, window=10):\n",
    "    \"\"\"\n",
    "    Tag event_id, event_date, and event_time for rows within ±window of any event,\n",
    "    while keeping all original rows (unmatched rows get NaN).\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): Must include ['Date', 'ticker', ...]\n",
    "        event_dict (dict): {'event_id': pd.Timestamp('YYYY-MM-DD')}\n",
    "        window (int): Matching window in days (default ±10)\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Same shape as input, with additional columns:\n",
    "                   ['event_id', 'event_date', 'event_time']\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"Date\"] = df[\"Date\"].dt.tz_localize(None)\n",
    "\n",
    "    tag_list = []\n",
    "\n",
    "    for event_id, event_date in event_dict.items():\n",
    "        temp = df.copy()\n",
    "        temp[\"event_time_candidate\"] = (temp[\"Date\"] - event_date).dt.days\n",
    "        temp[\"event_id_candidate\"] = event_id\n",
    "        temp[\"event_date_candidate\"] = event_date\n",
    "\n",
    "        # Keep only matches within window\n",
    "        temp = temp[\n",
    "            (temp[\"event_time_candidate\"] >= -window)\n",
    "            & (temp[\"event_time_candidate\"] <= window)\n",
    "        ]\n",
    "\n",
    "        tag_list.append(\n",
    "            temp[\n",
    "                [\n",
    "                    \"Date\",\n",
    "                    \"ticker\",\n",
    "                    \"event_id_candidate\",\n",
    "                    \"event_date_candidate\",\n",
    "                    \"event_time_candidate\",\n",
    "                ]\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # Combine all matches\n",
    "    tag_df = pd.concat(tag_list, ignore_index=True)\n",
    "\n",
    "    # Merge event info into original df\n",
    "    df = df.merge(tag_df, on=[\"Date\", \"ticker\"], how=\"left\")\n",
    "\n",
    "    # Rename columns\n",
    "    df.rename(\n",
    "        columns={\n",
    "            \"event_id_candidate\": \"event_id\",\n",
    "            \"event_date_candidate\": \"event_date\",\n",
    "            \"event_time_candidate\": \"event_time\",\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def compute_car_pre_post_delta_full(df, pre_window=(-10, -1), post_window=(0, 10)):\n",
    "    \"\"\"\n",
    "    Compute CAR_pre, CAR_post, delta_CAR, and post indicator for all rows,\n",
    "    without filtering any row. Only rows in [–10, +10] contribute to CAR computation,\n",
    "    but all rows are kept.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): Must include ['Date', 'ticker', 'event_date', 'abnormal_return']\n",
    "        pre_window (tuple): (start_day, end_day) for CAR_pre (e.g., (-10, -1))\n",
    "        post_window (tuple): for CAR_post (e.g., (0, 10))\n",
    "\n",
    "    Returns:\n",
    "        df (DataFrame): original df with added columns: ['event_time', 'CAR_pre', 'CAR_post', 'delta_CAR', 'post', 'CAR']\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "    df[\"event_date\"] = pd.to_datetime(df[\"event_date\"])\n",
    "\n",
    "    # Step 1: Compute event_time for all rows\n",
    "    df[\"event_time\"] = (df[\"Date\"] - df[\"event_date\"]).dt.days\n",
    "\n",
    "    # Step 2: Compute CAR_pre from [–10, –1]\n",
    "    pre_df = (\n",
    "        df[(df[\"event_time\"] >= pre_window[0]) & (df[\"event_time\"] <= pre_window[1])]\n",
    "        .groupby([\"ticker\", \"event_date\"])[\"abnormal_return\"]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "    )\n",
    "    pre_df.rename(columns={\"abnormal_return\": \"CAR_pre\"}, inplace=True)\n",
    "\n",
    "    # Step 3: Compute CAR_post from [0, +10]\n",
    "    post_df = (\n",
    "        df[(df[\"event_time\"] >= post_window[0]) & (df[\"event_time\"] <= post_window[1])]\n",
    "        .groupby([\"ticker\", \"event_date\"])[\"abnormal_return\"]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "    )\n",
    "    post_df.rename(columns={\"abnormal_return\": \"CAR_post\"}, inplace=True)\n",
    "\n",
    "    # Step 4: Merge CARs back into full df\n",
    "    df = df.merge(pre_df, on=[\"ticker\", \"event_date\"], how=\"left\")\n",
    "    df = df.merge(post_df, on=[\"ticker\", \"event_date\"], how=\"left\")\n",
    "\n",
    "    # Step 5: Compute delta_CAR and post indicator\n",
    "    df[\"delta_CAR\"] = df[\"CAR_post\"] - df[\"CAR_pre\"]\n",
    "    df[\"post\"] = (df[\"Date\"] >= df[\"event_date\"]).astype(int)\n",
    "    \n",
    "    # Step 6: Construct CAR column = CAR_pre + CAR_post\n",
    "    df[\"CAR\"] = df[\"CAR_pre\"] + df[\"CAR_post\"]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "079d95af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17442, 7)\n",
      "Treatment\n",
      "0    9234\n",
      "1    8208\n",
      "Name: count, dtype: int64\n",
      "['NVDA' 'AMD' 'INTC' 'MU' 'AVGO' 'QCOM' 'MRVL' 'TSM' 'CRM' 'ORCL' 'ADBE'\n",
      " 'NOW' 'CRWD' 'MDB' 'INTU' 'SNOW' 'QQQ']\n"
     ]
    }
   ],
   "source": [
    "# event_dict = {\n",
    "#     \"2021_china_tech_self_reliance\": pd.to_datetime(\"2021-03-01\"),  # China releases 14th Five-Year Plan emphasizing tech self-reliance\n",
    "#     \"2022_wto_steel_aluminum_dispute\": pd.to_datetime(\"2022-12-09\"),  # US rejects WTO ruling on steel and aluminum tariffs\n",
    "#     \"2023_chip_export_controls\": pd.to_datetime(\"2023-01-27\"),  # US and EU tighten controls on semiconductor technology exports to China\n",
    "#     \"2023_mineral_export_restrictions\": pd.to_datetime(\"2023-07-07\"),  # US criticizes China's export restrictions on critical minerals\n",
    "#     \"2024_tariff_increase_ev_battery\": pd.to_datetime(\"2024-05-14\"),  # US raises tariffs on EV batteries, solar panels, and metals\n",
    "#     \"2024_tariff_finalization\": pd.to_datetime(\"2024-09-13\"),  # US finalizes higher tariffs on EVs, batteries, critical minerals\n",
    "#     \"2024_nvidia_antitrust_probe\": pd.to_datetime(\"2024-12-10\"),  # China launches antitrust investigation into Nvidia\n",
    "# }\n",
    "\n",
    "event_dict = {\n",
    "    \"2022_oct_china_chip_export_control\": pd.to_datetime(\"2022-10-07\"),  # Biden administration restricts advanced AI chip exports to China\n",
    "    \"2023_chip_export_controls\": pd.to_datetime(\"2023-01-27\"),  # US and EU tighten controls on semiconductor technology exports to China\n",
    "    \"2023_export_expansion\": pd.to_datetime(\"2023-10-17\"),  # US expands export restrictions on semiconductors\n",
    "    \n",
    "    \"2023_mineral_export_restrictions\": pd.to_datetime(\"2023-07-07\"),  # China restricts critical mineral exports\n",
    "    \"2023_aug_investment_ban\": pd.to_datetime(\"2023-08-09\"),  # Biden signs executive order banning investments in Chinese AI/semiconductors\n",
    "    \"2024_march_export_tightening\": pd.to_datetime(\"2024-03-29\"),  # US tightens export licensing rules for AI semiconductors\n",
    "    \"2024_tariff_increase_ev_battery\": pd.to_datetime(\"2024-05-14\"),  # US raises tariffs on EV batteries, solar panels, and metals\n",
    "    \"2024_tariff_finalization\": pd.to_datetime(\"2024-09-13\"),  # US finalizes higher tariffs\n",
    "    \"2024_nvidia_antitrust_probe\": pd.to_datetime(\"2024-12-10\"),  # China launches antitrust investigation into Nvidia\n",
    "}\n",
    "\n",
    "\n",
    "# Treatment Group (Hardware-dependent AI companies)\n",
    "NVDA_df = daily_return_price(\"NVDA\", \"2020-12-31\", \"2025-2-1\", 1)  # NVIDIA\n",
    "AMD_df = daily_return_price(\"AMD\", \"2020-12-31\", \"2025-2-1\", 1)   # AMD\n",
    "INTC_df = daily_return_price(\"INTC\", \"2020-12-31\", \"2025-2-1\", 1)  # Intel\n",
    "MU_df = daily_return_price(\"MU\", \"2020-12-31\", \"2025-2-1\", 1)      # Micron\n",
    "AVGO_df = daily_return_price(\"AVGO\", \"2020-12-31\", \"2025-2-1\", 1)  # Broadcom\n",
    "QCOM_df = daily_return_price(\"QCOM\", \"2020-12-31\", \"2025-2-1\", 1)  # Qualcomm\n",
    "MRVL_df = daily_return_price(\"MRVL\", \"2020-12-31\", \"2025-2-1\", 1)  # Marvell Technology\n",
    "TSM_df = daily_return_price(\"TSM\", \"2020-12-31\", \"2025-2-1\", 1)  # TSMC\n",
    "\n",
    "\n",
    "# Control Group (Software/SaaS companies)\n",
    "CRM_df = daily_return_price(\"CRM\", \"2020-12-31\", \"2025-2-1\", 0)    # Salesforce\n",
    "ORCL_df = daily_return_price(\"ORCL\", \"2020-12-31\", \"2025-2-1\", 0)  # Oracle\n",
    "ADBE_df = daily_return_price(\"ADBE\", \"2020-12-31\", \"2025-2-1\", 0)  # Adobe\n",
    "NOW_df = daily_return_price(\"NOW\", \"2020-12-31\", \"2025-2-1\", 0)    # ServiceNow\n",
    "CRWD_df = daily_return_price(\"CRWD\", \"2020-12-31\", \"2025-2-1\", 0)  # CrowdStrike\n",
    "MDB_df = daily_return_price(\"MDB\", \"2020-12-31\", \"2025-2-1\", 0)  # MDB\n",
    "\n",
    "INTU_df = daily_return_price(\"INTU\", \"2020-12-31\", \"2025-2-1\", 0)  # Intuit\n",
    "SNOW_df = daily_return_price(\"SNOW\", \"2020-12-31\", \"2025-2-1\", 0)   # SNOW\n",
    "\n",
    "\n",
    "\n",
    "# Market Benchmark\n",
    "Market_df = daily_return_price(\"QQQ\", \"2020-12-31\", \"2025-2-1\", 0)\n",
    "Market_df[\"ticker\"] = \"QQQ\"\n",
    "\n",
    "# === 2. Apply Expected Return Rolling for Each Stock ===\n",
    "all_stocks = [\n",
    "    NVDA_df, AMD_df, INTC_df, MU_df, AVGO_df, QCOM_df, MRVL_df,TSM_df,\n",
    "    CRM_df, ORCL_df, ADBE_df,NOW_df, CRWD_df, MDB_df, INTU_df, SNOW_df, \n",
    "    Market_df\n",
    "]\n",
    "# all_stocks = [\n",
    "#     NVDA_df, AMD_df, INTC_df, MU_df, AVGO_df, QCOM_df, MRVL_df,TSM_df,\n",
    "#     CRM_df, ORCL_df, ADBE_df,NOW_df, CRWD_df, MDB_df, SNOW_df, CSCO_df, PLTR_df,\n",
    "#     Market_df\n",
    "# ]\n",
    "\n",
    "# Apply the rolling expected return calculation\n",
    "all_stocks = [compute_expected_return_rolling(stock) for stock in all_stocks]\n",
    "\n",
    "# === 3. Combine Everything into Final DataFrame ===\n",
    "final_df = pd.concat(all_stocks , ignore_index=True)\n",
    "\n",
    "print(final_df.shape)\n",
    "print(final_df['Treatment'].value_counts())\n",
    "print(final_df['ticker'].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "a9426a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tagged_df = tag_event_info_all_rows(final_df, event_dict, window=7)\n",
    "final_full_df = compute_car_pre_post_delta_full(final_tagged_df)\n",
    "\n",
    "final_full_df.to_csv(\"final_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "050d16c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_tagged_df = tag_event_info_all_rows(final_df, event_dict, window=10)\n",
    "# single_full_df = compute_car_pre_post_delta_full(single_tagged_df)\n",
    "\n",
    "# single_full_df.to_csv(\"single_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "ef1737cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'ticker', 'Close', 'Return', 'Treatment', 'expected_return',\n",
      "       'abnormal_return', 'event_id', 'event_date', 'event_time', 'CAR_pre',\n",
      "       'CAR_post', 'delta_CAR', 'post', 'CAR'],\n",
      "      dtype='object')\n",
      "Unique tickers: ['ADBE', 'AMD', 'AVGO', 'CRM', 'CRWD', 'INTC', 'INTU', 'MDB', 'MRVL', 'MU', 'NOW', 'NVDA', 'ORCL', 'QCOM', 'QQQ', 'SNOW', 'TSM']\n"
     ]
    }
   ],
   "source": [
    "print(final_full_df.columns)\n",
    "print(\"Unique tickers:\", sorted(final_full_df['ticker'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "0bf4f975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1026.0\n",
      "mean       17.0\n",
      "std         0.0\n",
      "min        17.0\n",
      "25%        17.0\n",
      "50%        17.0\n",
      "75%        17.0\n",
      "max        17.0\n",
      "Name: ticker, dtype: float64\n",
      "ticker\n",
      "17    1026\n",
      "Name: count, dtype: int64\n",
      " Dates with missing or extra tickers:\n",
      "Series([], Name: ticker, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "final_df[\"Date\"] = pd.to_datetime(final_df[\"Date\"], errors=\"coerce\")\n",
    "\n",
    "date_counts = final_df.groupby(\"Date\")[\"ticker\"].nunique()\n",
    "\n",
    "print(date_counts.describe())\n",
    "print(date_counts.value_counts())\n",
    "\n",
    "problem_dates = date_counts[date_counts != 17]\n",
    "print(\" Dates with missing or extra tickers:\")\n",
    "print(problem_dates)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
